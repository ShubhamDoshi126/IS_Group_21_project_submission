{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10182283,"sourceType":"datasetVersion","datasetId":6289969}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install numpy\n!pip install pandas\n!pip install tensorflow\n!pip install scikit-learn\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:23:01.540356Z","iopub.execute_input":"2024-12-12T15:23:01.540781Z","iopub.status.idle":"2024-12-12T15:23:44.708392Z","shell.execute_reply.started":"2024-12-12T15:23:01.540741Z","shell.execute_reply":"2024-12-12T15:23:44.706959Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nCollecting ml-dtypes~=0.3.1 (from tensorflow)\n  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.64.1)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.1.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\nDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ml-dtypes\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml_dtypes 0.5.0\n    Uninstalling ml_dtypes-0.5.0:\n      Successfully uninstalled ml_dtypes-0.5.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njax 0.4.35 requires ml-dtypes>=0.4.0, but you have ml-dtypes 0.3.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ml-dtypes-0.3.2\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\n\n# Define the file path for the dataset\nfile_path = \"/kaggle/input/combined-data/Combined Data.csv\"\n\ntry:\n    # Read the dataset using the ISO-8859-1 encoding, suitable for Windows-formatted files\n    df = pd.read_csv(file_path, index_col=0, encoding=\"ISO-8859-1\")\n    # Display a random sample of 5 rows from the dataset to verify data integrity\n    print(df.sample(5))\nexcept FileNotFoundError:\n    # Handle the case where the specified file is not found\n    print(f\"Error: File not found at {file_path}. Please check the file path.\")\nexcept Exception as e:\n    # Catch and display any other exceptions encountered during file reading\n    print(f\"An error occurred while reading the file: {e}\")\n\n# Extract features (statements) and labels (statuses) from the dataset\nX = df['statement'].tolist()\ny = df['status'].tolist()\n\n# Replace missing values in the features with empty strings\nX = [str(text) if not pd.isnull(text) else '' for text in X]\n\n# Initialize the tokenizer for text preprocessing\nmax_words = 5000  # Maximum number of words to keep in the vocabulary\nmax_len = 100     # Maximum sequence length for padding\n\n# Create the tokenizer and fit it on the text data\ntokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\ntokenizer.fit_on_texts(X)\n\n# Convert text data to sequences of integers\nX_sequences = tokenizer.texts_to_sequences(X)\n\n# Pad the sequences to ensure uniform length\nX_padded = pad_sequences(X_sequences, maxlen=max_len, truncating='post')\n\n# Encode the labels into numerical format using LabelEncoder\nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Convert the encoded labels to categorical format\ny_categorical = tf.keras.utils.to_categorical(y_encoded, num_classes=len(label_encoder.classes_))\n\n# Split the data into training, validation, and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_padded, y_categorical, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\n# Define the architecture of the sequential model\nmodel = Sequential([\n    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),  # Embedding layer for text input\n    LSTM(128, return_sequences=True),  # First LSTM layer with output returned at each timestep\n    Dropout(0.5),  # Dropout for regularization\n    LSTM(64),  # Second LSTM layer\n    Dense(64, activation='relu'),  # Fully connected layer with ReLU activation\n    Dropout(0.3),  # Dropout for regularization\n    Dense(len(label_encoder.classes_), activation='softmax')  # Output layer with softmax activation\n])\n\n# Compile the model with Adam optimizer and categorical crossentropy loss\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Set up callbacks for early stopping and model checkpointing\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nmodel_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_accuracy')\n\n# Train the model on the training data, with validation during training\nhistory = model.fit(\n    X_train, y_train,\n    epochs=50,  # Maximum number of epochs\n    batch_size=32,  # Batch size for training\n    validation_data=(X_val, y_val),  # Validation data\n    callbacks=[early_stopping, model_checkpoint]  # Callbacks for monitoring training\n)\n\n# Evaluate the model performance on the test data\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f'Test Loss: {loss:.4f}')\nprint(f'Test Accuracy: {accuracy:.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:30:05.643970Z","iopub.execute_input":"2024-12-12T15:30:05.644238Z","iopub.status.idle":"2024-12-12T15:35:50.820464Z","shell.execute_reply.started":"2024-12-12T15:30:05.644210Z","shell.execute_reply":"2024-12-12T15:35:50.819645Z"}},"outputs":[{"name":"stdout","text":"                                               statement    status\n71457  It must feel like theres a clock ticking loud...    Stress\n22206  I am a pitiful being and I just want to kill m...  Suicidal\n49119  How do I stop losing track of all the things I...    Stress\n45098  to transcode a 00mb wmv to a 00mb flv file wit...    Normal\n43624  is looking at the gray sky the sun ha been sto...    Normal\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m2001/2001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 12ms/step - accuracy: 0.7017 - loss: 0.8355 - val_accuracy: 0.8038 - val_loss: 0.4559\nEpoch 2/50\n\u001b[1m2001/2001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.8156 - loss: 0.4358 - val_accuracy: 0.8328 - val_loss: 0.3922\nEpoch 3/50\n\u001b[1m2001/2001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8594 - loss: 0.3555 - val_accuracy: 0.8696 - val_loss: 0.3378\nEpoch 4/50\n\u001b[1m2001/2001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.8832 - loss: 0.2890 - val_accuracy: 0.8744 - val_loss: 0.3224\nEpoch 5/50\n\u001b[1m2001/2001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.8997 - loss: 0.2539 - val_accuracy: 0.8776 - val_loss: 0.3255\nEpoch 6/50\n\u001b[1m2001/2001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.9146 - loss: 0.2208 - val_accuracy: 0.8776 - val_loss: 0.3357\nEpoch 7/50\n\u001b[1m2001/2001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.9236 - loss: 0.1993 - val_accuracy: 0.8767 - val_loss: 0.3547\nEpoch 8/50\n\u001b[1m2001/2001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9331 - loss: 0.1740 - val_accuracy: 0.8706 - val_loss: 0.3820\nEpoch 9/50\n\u001b[1m2001/2001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9375 - loss: 0.1707 - val_accuracy: 0.8744 - val_loss: 0.3941\nEpoch 10/50\n\u001b[1m2001/2001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.9469 - loss: 0.1404 - val_accuracy: 0.8716 - val_loss: 0.4009\nEpoch 11/50\n\u001b[1m2001/2001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.9562 - loss: 0.1203 - val_accuracy: 0.8704 - val_loss: 0.4534\nEpoch 12/50\n\u001b[1m2001/2001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9608 - loss: 0.1062 - val_accuracy: 0.8690 - val_loss: 0.4897\nEpoch 13/50\n\u001b[1m2001/2001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.9645 - loss: 0.0978 - val_accuracy: 0.8699 - val_loss: 0.5420\nEpoch 14/50\n\u001b[1m2001/2001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.9701 - loss: 0.0837 - val_accuracy: 0.8703 - val_loss: 0.5488\n\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8656 - loss: 0.3353\nTest Loss: 0.3270\nTest Accuracy: 0.8695\n","output_type":"stream"}],"execution_count":1}]}